{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 获取数据文件地址\n",
    "def getfilelist(dir, filelist):\n",
    "    newdir = dir\n",
    "    if os.path.isfile(dir):\n",
    "        filelist.append(dir)\n",
    "    elif os.path.isdir(dir):\n",
    "        for s in os.listdir(dir):\n",
    "            newdir = os.path.join(dir, s)\n",
    "            getfilelist(newdir, filelist)\n",
    "    return filelist\n",
    "\n",
    "\n",
    "#修改工作时长小于0的值（暂定成nan之后删除）\n",
    "def trans_to_nan (hours):\n",
    "    if hours <0:\n",
    "        hours = np.nan\n",
    "    return hours\n",
    "\n",
    "\n",
    "#数据处理，去除部件工作时长为负数的值,并且每个时间点只保留k个值\n",
    "def preprocess (path,k):\n",
    "\n",
    "    raw_data = pd.read_csv(path,engine='python')\n",
    "\n",
    "    #将部件工作时长<0的时长值改为nan并删除\n",
    "    # print(raw_data.columns)\n",
    "    \n",
    "    raw_data['部件工作时长'] = raw_data['部件工作时长'].map(lambda r:trans_to_nan(r))\n",
    "    raw_data = raw_data.dropna()\n",
    "\n",
    "    #每个工作时长至多保留k个值\n",
    "    #提取部件工作时长列作为list方便处理\n",
    "    raw_list = raw_data['部件工作时长'].tolist()\n",
    "    for i in range(len(raw_list)-k):\n",
    "        counter = 1\n",
    "        #找到重复项最后一项的索引\n",
    "        while counter + i < len(raw_list):\n",
    "            if raw_list[i] == raw_list[i+counter]:\n",
    "                counter += 1\n",
    "            else:\n",
    "                break\n",
    "        #判断是否需要删除数据\n",
    "        if counter <= k:\n",
    "            continue\n",
    "        else:\n",
    "            for m in range(counter-k):\n",
    "                raw_list[i+k+m] = np.nan\n",
    "    #修改dataframe对应列\n",
    "    raw_data['部件工作时长'] = raw_list\n",
    "    raw_data = raw_data.dropna()\n",
    "\n",
    "    return raw_data\n",
    "\n",
    "\n",
    "#处理单个单本的数据,添加单个样本的特征\n",
    "def feature_project (data,df,name,k):\n",
    "\n",
    "    #根据样本选择或处理特征\n",
    "\n",
    "    #开关与告警信号取其在总数据中的占比\n",
    "    if name == '开关1信号' or name == '开关2信号' or name == '告警信号1':\n",
    "        df[name + '时间占比'] = data.sum()/len(data)\n",
    "    \n",
    "    #温度信号取其均值与标准差为特征\n",
    "    elif name == '温度信号' or name == '流量信号':\n",
    "        df[name + '均值'] = data.mean()\n",
    "        df[name + '标准差'] = data.std()\n",
    "    \n",
    "    #累积量参数取最大值，k个周期的差分的均值与标准差作为特征\n",
    "    elif name == '累积量参数1' or name == '累积量参数2':\n",
    "        df[name] = data.max()\n",
    "        data = data.diff(periods = k)\n",
    "        data = data.dropna()\n",
    "        df[name + str(k) + '阶差分均值'] = data.mean()\n",
    "        df[name + str(k) + '阶差分标准差'] = data.std()\n",
    "\n",
    "    #电流信号主要集中分布在三段区间中，分别列出取均值与标准差，加权后取为特征\n",
    "    elif name == '电流信号':\n",
    "        length = len(data)\n",
    "        low_current = list(num for num in data if 0 <= num < 20)\n",
    "        mid_current = list(num for num in data if 500 <= num < 750)\n",
    "        high_current = list(num for num in data if 800 <= num < 1800)\n",
    "        low_percentage = np.sum(low_current) / length\n",
    "        mid_percentage = np.sum(mid_current) / length\n",
    "        high_percentage = np.sum(high_current) / length\n",
    "        df[name + '低电流段均值'] = np.mean(low_current) * low_percentage\n",
    "        df[name + '中电流段均值'] = np.mean(mid_current) * mid_percentage\n",
    "        df[name + '高电流段均值'] = np.mean(high_current) * high_percentage\n",
    "        df[name + '低电流段标准差'] = np.std(low_current) * low_percentage\n",
    "        df[name + '中电流段标准差'] = np.std(mid_current) * mid_percentage\n",
    "        df[name + '高电流段标准差'] = np.std(high_current) * high_percentage\n",
    "\n",
    "    #流量信号主要集中分布在三段区间中，分别列出取均值与标准差，加权后取为特征\n",
    "    elif name == '流量信号':\n",
    "        length = len(data)\n",
    "        low_current = list(num for num in data if 0 <= num < 9)\n",
    "        mid_current = list(num for num in data if 10 <= num < 120)\n",
    "        high_current = list(num for num in data if 125 <= num < 145)\n",
    "        low_percentage = np.sum(low_current) / length\n",
    "        mid_percentage = np.sum(mid_current) / length\n",
    "        high_percentage = np.sum(high_current) / length\n",
    "        df[name + '低流量段均值'] = np.mean(low_current) * low_percentage\n",
    "        df[name + '中流量段均值'] = np.mean(mid_current) * mid_percentage\n",
    "        df[name + '高流量段均值'] = np.mean(high_current) * high_percentage\n",
    "        df[name + '低流量段标准差'] = np.std(low_current) * low_percentage\n",
    "        df[name + '中流量段标准差'] = np.std(mid_current) * mid_percentage\n",
    "        df[name + '高流量段标准差'] = np.std(high_current) * high_percentage\n",
    "    \n",
    "    #压力信号1主要分布在两段区间上，同上取均值与标准差加权后取为特征\n",
    "    elif name == '压力信号1':\n",
    "        length = len(data)\n",
    "        low_pressure = list(num for num in data if 65 <= num <=75)\n",
    "        high_pressure = list(num for num in data if 180 <= num <= 400)\n",
    "        low_percentage = np.sum(low_pressure) / length\n",
    "        high_percentage = np.sum(high_pressure) / length\n",
    "        df[name + '信号1低压力段标准差'] = np.std(low_pressure) * low_percentage\n",
    "        df[name + '信号1高压力段标准差'] = np.std(high_pressure) * high_percentage\n",
    "    \n",
    "    #压力信号2主要分布在一段区间上，剩余值较小，处理同上\n",
    "    elif name == '压力信号2':\n",
    "        length = len(data)\n",
    "        low_pressure = list(num for num in data if 0 <= num <=50)\n",
    "        high_pressure = list(num for num in data if 200 <= num)\n",
    "        low_percentage = np.sum(low_pressure) / length\n",
    "        high_percentage = np.sum(high_pressure) / length\n",
    "        df[name + '信号2低压力段标准差'] = np.std(low_pressure) * low_percentage\n",
    "        df[name + '信号2高压力段标准差'] = np.std(high_pressure) * high_percentage\n",
    "\n",
    "    #同压力信号2\n",
    "    elif name == '转速信号1':\n",
    "        length = len(data)\n",
    "        low_pressure = list(num for num in data if 0 <= num <=100)\n",
    "        high_pressure = list(num for num in data if 3000 <= num)\n",
    "        low_percentage = np.sum(low_pressure) / length\n",
    "        high_percentage = np.sum(high_pressure) / length\n",
    "        df[name + '信号1低转速段均值'] = np.mean(low_pressure) * low_percentage\n",
    "        df[name + '信号1高转速段均值'] = np.mean(high_pressure) * high_percentage\n",
    "        df[name + '信号1低转速段标准差'] = np.std(low_pressure) * low_percentage\n",
    "        df[name + '信号1高转速段标准差'] = np.std(high_pressure) * high_percentage\n",
    "    \n",
    "    #同压力信号2\n",
    "    elif name == '转速信号2':\n",
    "        length = len(data)\n",
    "        low_pressure = list(num for num in data if 0 <= num <=1000)\n",
    "        high_pressure = list(num for num in data if 10000 <= num)\n",
    "        low_percentage = np.sum(low_pressure) / length\n",
    "        high_percentage = np.sum(high_pressure) / length\n",
    "        df[name + '信号2极低转速段均值'] = np.mean(low_pressure) * low_percentage\n",
    "        df[name + '信号2高转速段均值'] = np.mean(high_pressure) * high_percentage\n",
    "        df[name + '信号2极低转速段标准差'] = np.std(low_pressure) * low_percentage\n",
    "        df[name + '信号2高转速段标准差'] = np.std(high_pressure) * high_percentage\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#耦合特征构造\n",
    "def coupled_feature (dataframe,df):\n",
    "    \n",
    "    #取出列名表\n",
    "    column_list = dataframe.columns.values.tolist()\n",
    "    #循环将特征两两相乘组合\n",
    "    for i in range (3,13):\n",
    "        for j in range (i+1,13):\n",
    "#            mutiple = dataframe.iloc[:,[i]]*dataframe.iloc[:,[j]]\n",
    "            mutiple = dataframe.iloc[:,[i]].values * dataframe.iloc[:,[j]].values \n",
    "            df[column_list[i] +'与'+ column_list[j] +'乘积的均值'] = mutiple.mean()\n",
    "            df[column_list[i] +'与'+ column_list[j] +'乘积的标准差'] = mutiple.std()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#处理单个训练样本\n",
    "def process_sample_single(path,train_percentage=1,k=6):\n",
    "\n",
    "    #获取并预处理数据\n",
    "    data = preprocess(path,k)\n",
    "    #获取该零件寿命\n",
    "    work_life = data['部件工作时长'].max()\n",
    "    #获取在寿命一定百分比时间的数据\n",
    "    data=data[data['部件工作时长']<=work_life*train_percentage]\n",
    "    #创建数据集\n",
    "    dict_data = {'train_file_name': os.path.basename(path) + str(train_percentage),\n",
    "                 'device': data['设备类型'][0],\n",
    "                 '开关1_sum':data['开关1信号'].sum(),\n",
    "                 '开关2_sum':data['开关2信号'].sum(),\n",
    "                 '告警1_sum':data['告警信号1'].sum(),\n",
    "                 'current_life':np.log(data['部件工作时长'].max()+1),\n",
    "                 'rest_life':np.log(work_life-data['部件工作时长'].max()+1)\n",
    "                }\n",
    "\n",
    "    #单项特征\n",
    "    for item in ['部件工作时长',\n",
    "                    '累积量参数1',\n",
    "                    '累积量参数2',\n",
    "                    '转速信号1',\n",
    "                    '转速信号2',\n",
    "                    '压力信号1',\n",
    "                    '压力信号2',\n",
    "                    '温度信号',\n",
    "                    '流量信号',\n",
    "                    '电流信号',\n",
    "                    '开关1信号',\n",
    "                    '开关2信号',\n",
    "                    '告警信号1']:\n",
    "        dict_data=feature_project(data[item],dict_data,item,k)  \n",
    "\n",
    "    #耦合特征\n",
    "    dict_data=coupled_feature(data,dict_data)\n",
    "\n",
    "    features = pd.DataFrame(dict_data, index=[0])\n",
    "    return features\n",
    "\n",
    "# 多进程调用单文件处理函数，并整合到一起\n",
    "def get_together(cpu, listp,istest,func):\n",
    "\n",
    "    if istest :\n",
    "            train_p_list=[1]\n",
    "            rst = []\n",
    "            pool = Pool(cpu)\n",
    "            for e in listp:\n",
    "                for train_p in train_p_list:\n",
    "                    rst.append(pool.apply_async(func, args=(e,train_p,)))\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            \n",
    "            # print(rst[0])\n",
    "            \n",
    "            rst = [i.get() for i in rst]\n",
    "            \n",
    "            # print(rst[0]) \n",
    "            \n",
    "            tv_features=rst[0]\n",
    "            for i in rst[1:]:\n",
    "                tv_features = pd.concat([tv_features, i], axis=0)\n",
    "            cols=tv_features.columns.tolist()\n",
    "            \n",
    "            try:      \n",
    "                for col in [idx,ycol]:\n",
    "                    cols.remove(col)\n",
    "                cols=[idx]+cols+[ycol]\n",
    "            except:\n",
    "                cols=[idx]+cols+[ycol]\n",
    "                \n",
    "            tv_features[idx]=tv_features[idx].apply(lambda x:x[:-1])\n",
    "            tv_features=tv_features.reindex(columns=cols)\n",
    "    else:   \n",
    "        train_p_list=np.arange(0.01,1,0.02)    # [0.45,0.55,0.63,0.75,0.85]  #=list(np.arange(0.05,1,0.05))\n",
    "        rst = []\n",
    "        pool = Pool(cpu)\n",
    "        for e in listp:\n",
    "            for train_p in train_p_list:\n",
    "                # print train_p\n",
    "                rst.append(pool.apply_async(func, args=(e,train_p, )))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        # print(rst)\n",
    "        \n",
    "        f_list = []\n",
    "        \n",
    "        for i in tqdm(rst):\n",
    "            f_list.append(i.get())\n",
    "        # rst = [i.get() for i in tqdm(rst)]\n",
    "        rst = f_list\n",
    "        \n",
    "        \n",
    "        tv_features=rst[0]\n",
    "        for i in rst[1:]:\n",
    "            tv_features = pd.concat([tv_features, i], axis=0)\n",
    "        cols=tv_features.columns.tolist()\n",
    "        \n",
    "        try:      \n",
    "            for col in [idx,ycol]:\n",
    "                cols.remove(col)\n",
    "            cols=[idx]+cols+[ycol]\n",
    "        except:\n",
    "            cols=[idx]+cols+[ycol]\n",
    "            \n",
    "        tv_features=tv_features.reindex(columns=cols)\n",
    "\n",
    "    return tv_features\n",
    "\n",
    "#评价指标\n",
    "def compute_loss(target, predict):\n",
    "    temp = np.log(abs(target + 1)) - np.log(abs(predict + 1))\n",
    "    res = np.sqrt(np.dot(temp, temp) / len(temp))\n",
    "    return res\n",
    "\n",
    "#lgb\n",
    "def lgb_cv(train, params, fit_params,feature_names, nfold, seed,test):\n",
    "    train_pred = pd.DataFrame({\n",
    "        'true': train[ycol],\n",
    "        'pred': np.zeros(len(train))})\n",
    "    test_pred = pd.DataFrame({idx: test[idx], ycol: np.zeros(len(test))},columns=[idx,ycol])\n",
    "    kfolder = KFold(n_splits=nfold, shuffle=True, random_state=seed)\n",
    "    for fold_id, (trn_idx, val_idx) in enumerate(kfolder.split(train)):\n",
    "        print('\\nFold_{fold_id} Training ================================\\n'.format(fold_id = fold_id))\n",
    "        lgb_trn = lgb.Dataset(\n",
    "            data=train.iloc[trn_idx][feature_names],\n",
    "            label=train.iloc[trn_idx][ycol],\n",
    "            feature_name=feature_names)\n",
    "        lgb_val = lgb.Dataset(\n",
    "            data=train.iloc[val_idx][feature_names],\n",
    "            label=train.iloc[val_idx][ycol],\n",
    "            feature_name=feature_names)\n",
    "        lgb_reg = lgb.train(params=params, train_set=lgb_trn,\n",
    "                            num_boost_round = fit_params['num_boost_round'], verbose_eval = fit_params['verbose_eval'],\n",
    "                            early_stopping_rounds = fit_params['early_stopping_rounds'], valid_sets=[lgb_trn, lgb_val])\n",
    "        val_pred = lgb_reg.predict(\n",
    "            train.iloc[val_idx][feature_names],\n",
    "            num_iteration=lgb_reg.best_iteration)\n",
    "        \n",
    "        train_pred.loc[val_idx, 'pred'] = val_pred\n",
    "        test_pred[ycol] += (np.exp(lgb_reg.predict(test[feature_names]))-1) \n",
    "    test_pred[ycol] = test_pred[ycol] / nfold\n",
    "    score = compute_loss(pd.Series(np.exp(train_pred['true']) - 1).apply(max, args=(0,))\n",
    "                         ,pd.Series(np.exp(train_pred['pred']) - 1).apply(max, args=(0,)))\n",
    "    print('\\nCV LOSS:', score)\n",
    "    return test_pred\n",
    "\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# import time\n",
    "# for i in tqdm(range(1,100,1)):\n",
    "#     time.sleep(1)\n",
    "#     print i\n",
    "idx='train_file_name'\n",
    "ycol='rest_life'\n",
    "\n",
    "# ====== lgb ======\n",
    "params_lgb = {'num_leaves': 250, \n",
    "              'max_depth':5, \n",
    "              'learning_rate': 0.01,\n",
    "              'objective': 'regression', \n",
    "              'boosting': 'gbdt',\n",
    "              'verbosity': -1}\n",
    "\n",
    "fit_params_lgb = {'num_boost_round': 800, \n",
    "                  'verbose_eval':200,\n",
    "                  'early_stopping_rounds': 30}\n",
    "\n",
    "# 执行主进程\n",
    "if __name__ == '__main__':\n",
    "    import time\n",
    "    start = time.time()\n",
    "    \n",
    "    train_list = getfilelist('train', [])\n",
    "    test_list = getfilelist('test1', [])\n",
    "    \n",
    "    n=4\n",
    "    func=process_sample_single\n",
    "    train=get_together(n,train_list,False,func)\n",
    "    test =get_together(n,test_list,True,func)\n",
    "    print(\"done.\", time.time()-start)\n",
    "\n",
    "\n",
    "    train.to_csv('train_total_features.csv', index=False)\n",
    "    test.to_csv('test_total_features.csv', index=False)\n",
    "    train.head()\n",
    "    test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train.columns:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_file_name</th>\n",
       "      <th>current_life</th>\n",
       "      <th>device</th>\n",
       "      <th>压力信号1与压力信号2乘积的均值</th>\n",
       "      <th>压力信号1与压力信号2乘积的标准差</th>\n",
       "      <th>压力信号1与告警信号1乘积的均值</th>\n",
       "      <th>压力信号1与告警信号1乘积的标准差</th>\n",
       "      <th>压力信号1与开关1信号乘积的均值</th>\n",
       "      <th>压力信号1与开关1信号乘积的标准差</th>\n",
       "      <th>压力信号1与开关2信号乘积的均值</th>\n",
       "      <th>...</th>\n",
       "      <th>转速信号2与流量信号乘积的标准差</th>\n",
       "      <th>转速信号2与温度信号乘积的均值</th>\n",
       "      <th>转速信号2与温度信号乘积的标准差</th>\n",
       "      <th>转速信号2与电流信号乘积的均值</th>\n",
       "      <th>转速信号2与电流信号乘积的标准差</th>\n",
       "      <th>转速信号2信号2极低转速段均值</th>\n",
       "      <th>转速信号2信号2极低转速段标准差</th>\n",
       "      <th>转速信号2信号2高转速段均值</th>\n",
       "      <th>转速信号2信号2高转速段标准差</th>\n",
       "      <th>rest_life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5767e300dd3a929fb6c5.csv0.7299999999999999</td>\n",
       "      <td>7.523211</td>\n",
       "      <td>S51d</td>\n",
       "      <td>38039.019182</td>\n",
       "      <td>24750.398619</td>\n",
       "      <td>0.201669</td>\n",
       "      <td>5.448333</td>\n",
       "      <td>63.420658</td>\n",
       "      <td>88.238148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>927464.052368</td>\n",
       "      <td>1.099919e+06</td>\n",
       "      <td>433151.435056</td>\n",
       "      <td>4.600476e+07</td>\n",
       "      <td>1.911685e+07</td>\n",
       "      <td>105.444801</td>\n",
       "      <td>181.793188</td>\n",
       "      <td>4.259512e+08</td>\n",
       "      <td>1.481424e+08</td>\n",
       "      <td>6.530148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>941021344dd1961e0974.csv0.35</td>\n",
       "      <td>6.388141</td>\n",
       "      <td>Saa3</td>\n",
       "      <td>56343.237409</td>\n",
       "      <td>34008.513838</td>\n",
       "      <td>0.060518</td>\n",
       "      <td>1.880349</td>\n",
       "      <td>116.511651</td>\n",
       "      <td>113.731290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>808736.946494</td>\n",
       "      <td>1.057191e+06</td>\n",
       "      <td>366816.078649</td>\n",
       "      <td>2.003750e+07</td>\n",
       "      <td>1.085180e+07</td>\n",
       "      <td>925.579800</td>\n",
       "      <td>845.516734</td>\n",
       "      <td>3.694063e+08</td>\n",
       "      <td>1.082009e+08</td>\n",
       "      <td>7.008279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fa5979704821986a1f74.csv0.7099999999999999</td>\n",
       "      <td>7.090702</td>\n",
       "      <td>Saa3</td>\n",
       "      <td>59537.698294</td>\n",
       "      <td>43840.422166</td>\n",
       "      <td>1.052775</td>\n",
       "      <td>14.697357</td>\n",
       "      <td>118.338423</td>\n",
       "      <td>137.932076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>717292.956722</td>\n",
       "      <td>9.233582e+05</td>\n",
       "      <td>289639.181064</td>\n",
       "      <td>2.213618e+07</td>\n",
       "      <td>8.427127e+06</td>\n",
       "      <td>63.986891</td>\n",
       "      <td>47.706328</td>\n",
       "      <td>3.175768e+08</td>\n",
       "      <td>9.628874e+07</td>\n",
       "      <td>6.232939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620b71882ffe5d7a3142.csv0.8299999999999998</td>\n",
       "      <td>8.670172</td>\n",
       "      <td>S26a</td>\n",
       "      <td>50001.777266</td>\n",
       "      <td>31648.720417</td>\n",
       "      <td>1.540497</td>\n",
       "      <td>24.446939</td>\n",
       "      <td>108.820002</td>\n",
       "      <td>110.318677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>653665.161033</td>\n",
       "      <td>1.011937e+06</td>\n",
       "      <td>507231.470213</td>\n",
       "      <td>1.911793e+07</td>\n",
       "      <td>1.042981e+07</td>\n",
       "      <td>42.942266</td>\n",
       "      <td>163.648809</td>\n",
       "      <td>3.124047e+08</td>\n",
       "      <td>8.573935e+07</td>\n",
       "      <td>7.095272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f473ef8589e0d5a74d00.csv0.8699999999999999</td>\n",
       "      <td>8.909674</td>\n",
       "      <td>S26a</td>\n",
       "      <td>77151.662561</td>\n",
       "      <td>47615.165142</td>\n",
       "      <td>0.271248</td>\n",
       "      <td>6.153255</td>\n",
       "      <td>201.958188</td>\n",
       "      <td>154.605073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>662948.421468</td>\n",
       "      <td>1.255727e+06</td>\n",
       "      <td>447130.422801</td>\n",
       "      <td>2.323217e+07</td>\n",
       "      <td>7.267486e+06</td>\n",
       "      <td>8.703783</td>\n",
       "      <td>17.474922</td>\n",
       "      <td>4.010860e+08</td>\n",
       "      <td>9.794602e+07</td>\n",
       "      <td>7.010763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              train_file_name  current_life device  \\\n",
       "0  5767e300dd3a929fb6c5.csv0.7299999999999999      7.523211   S51d   \n",
       "0                941021344dd1961e0974.csv0.35      6.388141   Saa3   \n",
       "0  fa5979704821986a1f74.csv0.7099999999999999      7.090702   Saa3   \n",
       "0  620b71882ffe5d7a3142.csv0.8299999999999998      8.670172   S26a   \n",
       "0  f473ef8589e0d5a74d00.csv0.8699999999999999      8.909674   S26a   \n",
       "\n",
       "   压力信号1与压力信号2乘积的均值  压力信号1与压力信号2乘积的标准差  压力信号1与告警信号1乘积的均值  压力信号1与告警信号1乘积的标准差  \\\n",
       "0      38039.019182       24750.398619          0.201669           5.448333   \n",
       "0      56343.237409       34008.513838          0.060518           1.880349   \n",
       "0      59537.698294       43840.422166          1.052775          14.697357   \n",
       "0      50001.777266       31648.720417          1.540497          24.446939   \n",
       "0      77151.662561       47615.165142          0.271248           6.153255   \n",
       "\n",
       "   压力信号1与开关1信号乘积的均值  压力信号1与开关1信号乘积的标准差  压力信号1与开关2信号乘积的均值    ...      \\\n",
       "0         63.420658          88.238148               0.0    ...       \n",
       "0        116.511651         113.731290               0.0    ...       \n",
       "0        118.338423         137.932076               0.0    ...       \n",
       "0        108.820002         110.318677               0.0    ...       \n",
       "0        201.958188         154.605073               0.0    ...       \n",
       "\n",
       "   转速信号2与流量信号乘积的标准差  转速信号2与温度信号乘积的均值  转速信号2与温度信号乘积的标准差  转速信号2与电流信号乘积的均值  \\\n",
       "0     927464.052368     1.099919e+06     433151.435056     4.600476e+07   \n",
       "0     808736.946494     1.057191e+06     366816.078649     2.003750e+07   \n",
       "0     717292.956722     9.233582e+05     289639.181064     2.213618e+07   \n",
       "0     653665.161033     1.011937e+06     507231.470213     1.911793e+07   \n",
       "0     662948.421468     1.255727e+06     447130.422801     2.323217e+07   \n",
       "\n",
       "   转速信号2与电流信号乘积的标准差  转速信号2信号2极低转速段均值  转速信号2信号2极低转速段标准差  转速信号2信号2高转速段均值  \\\n",
       "0      1.911685e+07       105.444801        181.793188    4.259512e+08   \n",
       "0      1.085180e+07       925.579800        845.516734    3.694063e+08   \n",
       "0      8.427127e+06        63.986891         47.706328    3.175768e+08   \n",
       "0      1.042981e+07        42.942266        163.648809    3.124047e+08   \n",
       "0      7.267486e+06         8.703783         17.474922    4.010860e+08   \n",
       "\n",
       "   转速信号2信号2高转速段标准差  rest_life  \n",
       "0     1.481424e+08   6.530148  \n",
       "0     1.082009e+08   7.008279  \n",
       "0     9.628874e+07   6.232939  \n",
       "0     8.573935e+07   7.095272  \n",
       "0     9.794602e+07   7.010763  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(frac=0.2, random_state=10).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_train_data(test, train, frac_start, frac_end, seed):\n",
    "    \n",
    "    shuffle_train = shuffle(train[train['train_file_name'].apply(lambda x: (float(x.split('.csv')[1])) >= 0.35 and (float(x.split('.csv')[1]) <= 0.85))], random_state = seed)\n",
    "    sub_train = shuffle_train.iloc[int(frac_start*len(shuffle_train)):int((frac_end)*len(shuffle_train)), :]\n",
    "    \n",
    "    result_list = []\n",
    "    \n",
    "    for device in ['S100', 'S26a', 'Saa3', 'S51d', 'S508']:\n",
    "        used_train_device_list = []\n",
    "        used_train_device_percentile_list = []\n",
    "        merged_df_list = []\n",
    "        test_device = test.query('device==\"{device}\"'.format(device=device))\n",
    "        train_device = sub_train.query('device==\"{device}\"'.format(device=device))\n",
    "        \n",
    "        left = test_device[[u'train_file_name',u'current_life']] ### .sort_values(u'current_life')\n",
    "        left.columns = ['test_file_name','current_life']\n",
    "        right = train_device[[u'train_file_name',u'current_life']].sort_values(u'current_life')\n",
    "        right.columns=  ['train_file_name','train_current_life']\n",
    "        \n",
    "        index_col = right['train_file_name'].apply(lambda x: x.split('.csv')[0])\n",
    "        \n",
    "        for i in range(len(left)):\n",
    "            tmp_left = left.iloc[i:i+1,:]\n",
    "            tmp_right = right[~index_col.isin(used_train_device_list)]\n",
    "            merged_df = pd.merge_asof(left = tmp_left, right = tmp_right, direction='nearest', left_on = u'current_life',right_on = u'train_current_life' )\n",
    "            \n",
    "            ## 如果匹配差异大，放宽多样性限制\n",
    "            if abs(list(merged_df['current_life'])[0] - list(merged_df['train_current_life'])[0]) < 1:\n",
    "                tmp_right = right[~right['train_file_name'].isin(used_train_device_percentile_list)]\n",
    "                merged_df = pd.merge_asof(left = tmp_left, right = tmp_right, direction='nearest', left_on = u'current_life',right_on = u'train_current_life' )\n",
    "            \n",
    "            fname = list(merged_df['train_file_name'])[0]\n",
    "            try:\n",
    "                used_train_device_list.append(list(merged_df['train_file_name'])[0].split('.csv')[0])\n",
    "                used_train_device_percentile_list.append(list(merged_df['train_file_name'])[0])\n",
    "                merged_df_list.append(merged_df.copy())\n",
    "            except:\n",
    "                # 如果没匹配到，放宽多样性限制\n",
    "                                \n",
    "                tmp_right = right[~right['train_file_name'].isin(used_train_device_percentile_list)]\n",
    "                merged_df = pd.merge_asof(left = tmp_left, right = tmp_right, direction='nearest', left_on = u'current_life',right_on = u'train_current_life' )\n",
    "                ## print merged_df\n",
    "                merged_df_list.append(merged_df.copy())\n",
    "\n",
    "        result_list.append(pd.concat(merged_df_list))\n",
    "    \n",
    "    return pd.concat(result_list).drop_duplicates()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_merge_list = []\n",
    "\n",
    "for i in tqdm(range(50)):\n",
    "    for frac in (0.0, 0.5):\n",
    "        train_0807 = get_similar_train_data(test, train, frac, frac+0.5, i)\n",
    "        train_files_df = train_0807[['train_file_name']]\n",
    "        train_files_df.columns = ['train_files_subset']\n",
    "        \n",
    "        new_train = pd.merge(train_files_df, train, left_on = 'train_files_subset', right_on = 'train_file_name',how='left')\n",
    "        new_train = new_train.drop(['train_files_subset'], axis=1)\n",
    "\n",
    "        train_test=pd.concat([new_train,test],join='outer',axis=0).reset_index(drop=True)\n",
    "        train_test=pd.get_dummies(train_test,columns=['device'])\n",
    "\n",
    "        nfold = 5\n",
    "        seed = 4096\n",
    "\n",
    "        column_names = train_test.columns.values.tolist()\n",
    "        special_column_names = ['device_S100','device_S26a','device_S508','device_S51d','device_Saa3','开关1_sum','开关2_sum','告警1_sum']\n",
    "        special_column_names = [idx] + ['current_life'] + special_column_names + [ycol]\n",
    "\n",
    "        for item in special_column_names:\n",
    "            column_names.remove(item)\n",
    "\n",
    "        train_test.fillna(0,inplace=True)\n",
    "        \n",
    "        for item in column_names:\n",
    "            std_temp = train_test[item].std()\n",
    "\n",
    "            if std_temp <= 1:\n",
    "                train_test[item] = np.exp(train_test[item])\n",
    "                std_temp2 = train_test[item].std()\n",
    "\n",
    "                #check the standard deviation again\n",
    "                if std_temp2 < 1:\n",
    "                    del train_test[item]\n",
    "\n",
    "            elif std_temp > 10:\n",
    "                train_test[item] = np.log(train_test[item] + 1)  \n",
    "                \n",
    "        feature_name=list(filter(lambda x:x not in[idx,ycol],train_test.columns))\n",
    "\n",
    "        sub = lgb_cv(train_test.iloc[:new_train.shape[0]] ,params_lgb, fit_params_lgb, \n",
    "                    feature_name, nfold,seed,train_test.iloc[new_train.shape[0]:])\n",
    "        \n",
    "\n",
    "        before_merge_list.append(sub)\n",
    "    \n",
    "sub_result_0807v1 = pd.concat(before_merge_list).groupby('train_file_name').mean().reset_index()\n",
    "## LOSS 0.64\n",
    "sub_result_0807v1.to_csv('resample_0807_sub_distinct_magic_number3585_100model.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----以下可忽略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rest_life    1275.12786\n",
       "dtype: float64"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(before_merge_list).groupby('train_file_name').mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rest_life    1400.339959\n",
       "dtype: float64"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(before_merge_list).groupby('train_file_name').mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rest_life    1587.950391\n",
       "dtype: float64"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(before_merge_list).groupby('train_file_name').mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88900"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.concat(before_merge_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_result_0807v3 = pd.concat(before_merge_list).groupby('train_file_name').mean().reset_index()\n",
    "## LOSS 0.81\n",
    "sub_result_0807v3.to_csv('resample_0807_sub_distinct_magic_number1585_100model.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_result_0807v2 = pd.concat(before_merge_list).groupby('train_file_name').mean().reset_index()\n",
    "## LOSS 0.71\n",
    "sub_result_0807v2.to_csv('resample_0807_sub_distinct_magic_number2585_100model.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat(before_merge_list).groupby('train_file_name').std().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_result_0807v1 = pd.concat(before_merge_list).groupby('train_file_name').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOSS 0.64\n",
    "sub_result_0807v1.to_csv('resample_0807_sub_distinct_magic_number3585_100model.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(10)):\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0806 = get_similar_train_data(test, train, 0.5, 1, 666) ## ['train_file_name'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_0806['train_file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_life</th>\n",
       "      <th>train_current_life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.116444</td>\n",
       "      <td>6.115892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.158230</td>\n",
       "      <td>8.157800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.102499</td>\n",
       "      <td>7.106196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.345693</td>\n",
       "      <td>8.344921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.894403</td>\n",
       "      <td>5.890262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   current_life  train_current_life\n",
       "0      6.116444            6.115892\n",
       "0      8.158230            8.157800\n",
       "0      7.102499            7.106196\n",
       "0      8.345693            8.344921\n",
       "0      5.894403            5.890262"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0806[['current_life','train_current_life']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                             889\n",
       "unique                                            889\n",
       "top       fa5979704821986a1f74.csv0.44999999999999996\n",
       "freq                                                1\n",
       "Name: train_file_name, dtype: object"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0806['train_file_name'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files_df = train_0806[['train_file_name']]\n",
    "train_files_df.columns = ['train_files_subset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "current_life          7.264929\n",
       "train_current_life    7.267529\n",
       "dtype: float64"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0806.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_files_df = concat_df[['train_file_name']]\n",
    "# train_files_df.columns = ['train_files_subset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.merge(train_files_df, train, left_on = 'train_files_subset', right_on = 'train_file_name',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = new_train.drop(['train_files_subset'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test=pd.concat([new_train,test],join='outer',axis=0).reset_index(drop=True)\n",
    "train_test=pd.get_dummies(train_test,columns=['device'])\n",
    "#    feature_name=list(filter(lambda x:x not in[idx,ycol],train_test.columns))\n",
    "\n",
    "nfold = 5\n",
    "seed = 4096\n",
    "\n",
    "column_names = train_test.columns.values.tolist()\n",
    "special_column_names = ['device_S100','device_S26a','device_S508','device_S51d','device_Saa3','开关1_sum','开关2_sum','告警1_sum']\n",
    "special_column_names = [idx] + ['current_life'] + special_column_names + [ycol]\n",
    "\n",
    "for item in special_column_names:\n",
    "    column_names.remove(item)\n",
    "\n",
    "train_test.fillna(0,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in column_names:\n",
    "    std_temp = train_test[item].std()\n",
    "\n",
    "    if std_temp <= 1:\n",
    "        train_test[item] = np.exp(train_test[item])\n",
    "        std_temp2 = train_test[item].std()\n",
    "\n",
    "        #check the standard deviation again\n",
    "        if std_temp2 < 1:\n",
    "            del train_test[item]\n",
    "\n",
    "    elif std_temp > 10:\n",
    "        train_test[item] = np.log(train_test[item] + 1)\n",
    "\n",
    "#    column_diff_names = ['累积量参数16阶差分均值','累积量参数16阶差分标准差','累积量参数26阶差分均值','累积量参数26阶差分标准差']\n",
    "#    \n",
    "#    for item in column_diff_names:\n",
    "#        \n",
    "#        del train_test[item]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "\n",
    "# ====== lgb ======\n",
    "params_lgb = {'num_leaves': 250, \n",
    "              'max_depth':5, \n",
    "              'learning_rate': 0.01,\n",
    "              'objective': 'regression', \n",
    "              'boosting': 'gbdt',\n",
    "              'verbosity': -1}\n",
    "\n",
    "fit_params_lgb = {'num_boost_round': 800, \n",
    "                  'verbose_eval':200,\n",
    "                  'early_stopping_rounds': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name=list(filter(lambda x:x not in[idx,ycol],train_test.columns))\n",
    "\n",
    "sub= lgb_cv(train_test.iloc[:new_train.shape[0]] ,params_lgb, fit_params_lgb, \n",
    "            feature_name, nfold,seed,train_test.iloc[new_train.shape[0]:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub7 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub6 = sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub5 = sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub0806_v3 = sub5.copy()\n",
    "sub0806_v3['rest_life'] = (sub5['rest_life'] + sub6['rest_life']) / 2\n",
    "sub0806_v3.to_csv('resample_0806_sub_distinct_magic_number_35_85.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub4 = sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub3 = sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub0806_v2 = sub3.copy()\n",
    "sub0806_v2['rest_life'] = (sub3['rest_life'] + sub4['rest_life']) / 2\n",
    "sub0806_v2.to_csv('resample_0806_sub_distinct_no_magic_number.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2 = sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub0806_v1 = sub1.copy()\n",
    "sub0806_v1['rest_life'] = (sub1['rest_life'] + sub2['rest_life']) / 2\n",
    "sub0806_v1.to_csv('resample_0806_sub_distinct.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub0806_v1['rest_life'] = sub0806_v1['rest_life'] / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub0806_v1.to_csv('resample_0806_sub_distinct.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_file_name</th>\n",
       "      <th>rest_life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>13df215673fe44d8dae5.csv</td>\n",
       "      <td>283.168650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>8b3086c25931ade73b97.csv</td>\n",
       "      <td>3000.809740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>fc31ec603291154b51bc.csv</td>\n",
       "      <td>362.127285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>c00f30bb30fd5348984d.csv</td>\n",
       "      <td>1646.427478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>8a5426b1c63a6cf107c4.csv</td>\n",
       "      <td>205.299930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train_file_name    rest_life\n",
       "889  13df215673fe44d8dae5.csv   283.168650\n",
       "890  8b3086c25931ade73b97.csv  3000.809740\n",
       "891  fc31ec603291154b51bc.csv   362.127285\n",
       "892  c00f30bb30fd5348984d.csv  1646.427478\n",
       "893  8a5426b1c63a6cf107c4.csv   205.299930"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_file_name</th>\n",
       "      <th>rest_life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>13df215673fe44d8dae5.csv</td>\n",
       "      <td>368.879807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>8b3086c25931ade73b97.csv</td>\n",
       "      <td>2586.860969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>fc31ec603291154b51bc.csv</td>\n",
       "      <td>419.896425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>c00f30bb30fd5348984d.csv</td>\n",
       "      <td>1434.700117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>8a5426b1c63a6cf107c4.csv</td>\n",
       "      <td>280.516224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train_file_name    rest_life\n",
       "889  13df215673fe44d8dae5.csv   368.879807\n",
       "890  8b3086c25931ade73b97.csv  2586.860969\n",
       "891  fc31ec603291154b51bc.csv   419.896425\n",
       "892  c00f30bb30fd5348984d.csv  1434.700117\n",
       "893  8a5426b1c63a6cf107c4.csv   280.516224"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('resample_0804_sub_round_01_800_trunc_upper_v4.csv',index=False)\n",
    "print(\"process(es) done.\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "\n",
    "# ====== lgb ======\n",
    "params_lgb = {'num_leaves': 250, \n",
    "              'max_depth':5, \n",
    "              'learning_rate': 0.01,\n",
    "              'objective': 'regression', \n",
    "              'boosting': 'gbdt',\n",
    "              'verbosity': -1}\n",
    "\n",
    "fit_params_lgb = {'num_boost_round': 900, \n",
    "                  'verbose_eval':200,\n",
    "                  'early_stopping_rounds': 30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name=list(filter(lambda x:x not in[idx,ycol],train_test.columns))\n",
    "\n",
    "sub= lgb_cv(train_test.iloc[:new_train.shape[0]] ,params_lgb, fit_params_lgb, \n",
    "            feature_name, nfold,seed,train_test.iloc[new_train.shape[0]:])\n",
    "\n",
    "sub.to_csv('resample_0804_sub_round_01_900_v2.csv',index=False)\n",
    "print(\"process(es) done.\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8890.000000\n",
       "mean      464.371363\n",
       "std       505.579956\n",
       "min        15.542906\n",
       "25%       113.582777\n",
       "50%       298.442197\n",
       "75%       657.308592\n",
       "max      5166.498872\n",
       "Name: rest_life, dtype: float64"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.exp(new_train['rest_life']-1)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rest_life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>889.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1075.912420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>866.226476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>97.912072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>338.623033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>869.317808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1662.952330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7128.778048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rest_life\n",
       "count   889.000000\n",
       "mean   1075.912420\n",
       "std     866.226476\n",
       "min      97.912072\n",
       "25%     338.623033\n",
       "50%     869.317808\n",
       "75%    1662.952330\n",
       "max    7128.778048"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in feature_name:\n",
    "#     print type(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name=list(filter(lambda x:x not in[idx,ycol],train_test.columns))\n",
    "\n",
    "sub= lgb_cv(train_test.iloc[:train.shape[0]] ,params_lgb, fit_params_lgb, \n",
    "            feature_name, nfold,seed,train_test.iloc[train.shape[0]:])\n",
    "\n",
    "sub.to_csv('baseline_sub8.csv',index=False)\n",
    "print(\"process(es) done.\", time.time()-start)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\"\"\"\n",
    "绘制直方图\n",
    "data:必选参数，绘图数据\n",
    "bins:直方图的长条形数目，可选项，默认为10\n",
    "normed:是否将得到的直方图向量归一化，可选项，默认为0，代表不归一化，显示频数。normed=1，表示归一化，显示频率。\n",
    "facecolor:长条形的颜色\n",
    "edgecolor:长条形边框的颜色\n",
    "alpha:透明度\n",
    "\"\"\"\n",
    "\n",
    "account = 0\n",
    "\n",
    "for item in feature_name:\n",
    "    plt.subplot(11,11,1+account)\n",
    "    plt.title('Feature_name:{0}'.format(item))\n",
    "    plt.hist(train_test[item], bins=20, normed=0, facecolor=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "    account += 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1        True\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "5        True\n",
       "6       False\n",
       "7       False\n",
       "8       False\n",
       "9       False\n",
       "10       True\n",
       "11       True\n",
       "12       True\n",
       "13       True\n",
       "14       True\n",
       "15      False\n",
       "16       True\n",
       "17      False\n",
       "18       True\n",
       "19       True\n",
       "20      False\n",
       "21       True\n",
       "22      False\n",
       "23       True\n",
       "24      False\n",
       "25       True\n",
       "26      False\n",
       "27      False\n",
       "28      False\n",
       "29      False\n",
       "        ...  \n",
       "8860     True\n",
       "8861     True\n",
       "8862     True\n",
       "8863     True\n",
       "8864     True\n",
       "8865     True\n",
       "8866     True\n",
       "8867     True\n",
       "8868     True\n",
       "8869     True\n",
       "8870     True\n",
       "8871     True\n",
       "8872     True\n",
       "8873     True\n",
       "8874     True\n",
       "8875     True\n",
       "8876     True\n",
       "8877     True\n",
       "8878     True\n",
       "8879    False\n",
       "8880    False\n",
       "8881     True\n",
       "8882     True\n",
       "8883     True\n",
       "8884     True\n",
       "8885     True\n",
       "8886     True\n",
       "8887     True\n",
       "8888     True\n",
       "8889     True\n",
       "Name: train_file_name, Length: 8890, dtype: bool"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train['train_file_name'].apply(lambda x: float(x.split('.csv')[1])) >= 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
